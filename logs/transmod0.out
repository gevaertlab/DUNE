
[1;35m
Processing model = transmod/transmUNET[0m
/var/spool/slurmd/job14180/slurm_script: line 33: nvidia-smi: command not found
Importing outputs/transmod/transmUNET/config.cfg...
Traceback (most recent call last):
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae2.py", line 166, in <module>
    main(config)
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae2.py", line 131, in main
    torch.load(model_path + "/exports/best_model.pt"))
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 809, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 1172, in _load
    result = unpickler.load()
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 1142, in persistent_load
    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 1116, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 217, in default_restore_location
    result = fn(storage, location)
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/share/pi/ogevaert/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
