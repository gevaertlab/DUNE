Loading datasets...
Restoring previous...
Epoch 1/300
Train set...
  0%|[35m                                                                           [39m| 0/5322 [00:00<?, ?it/s]
torch.Size([1, 2048])
torch.Size([1, 128, 160, 192, 160])
torch.Size([1, 2048])
torch.Size([1, 128, 160, 192, 160])
torch.Size([1, 2048])
  0%|[35m                                                                           [39m| 0/5322 [01:08<?, ?it/s]
Traceback (most recent call last):
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae.py", line 245, in <module>
    main(**config)
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae.py", line 209, in main
    train_epoch_metrics = train_loop(
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae.py", line 52, in train_loop
    ssimloss = ssim_func(images, outputs[0], data_range=images.max())
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/monai/losses/ssim_loss.py", line 90, in forward
    raise ValueError(
ValueError: x and y should have the same number of channels, but x has 3 channels and y has 128 channels.