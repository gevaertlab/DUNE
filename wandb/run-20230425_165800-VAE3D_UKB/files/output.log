
Loading datasets...
Epoch 1/200
Train set...
  0%|[35m                                                                           [39m| 0/1995 [02:04<?, ?it/s]
Traceback (most recent call last):
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae.py", line 245, in <module>
    main(**config)
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae.py", line 209, in main
    train_epoch_metrics = train_loop(
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/train_ae.py", line 44, in train_loop
    outputs = model(images)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 89, in parallel_apply
    output.reraise()
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/newmods.py", line 158, in forward
    return self.decode(z), z, (mu, log_var)
  File "/home/tbarba/projects/MultiModalBrainSurvival/src/autoencoder/newmods.py", line 140, in decode
    result = self.final_layer(result)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/labs/gevaertlab/users/thomas/miniconda/envs/multimodal/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 294, in forward
    return torch.sigmoid(input)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 9.38 GiB (GPU 0; 15.77 GiB total capacity; 11.43 GiB already allocated; 3.14 GiB free; 11.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF